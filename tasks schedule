Collect and Preprocess Data: (Kyle 12/2)
Gather datasets (e.g., FakeNewsNet, LIAR).
Clean and tokenize text, extract features using TF-IDF, word embeddings, or transformers (e.g., BERT).

Model Selection:
(Trey 12/5)
Traditional: Logit, NB

(Rivas and Butters, Trey 12/5)
Deep Learning: LSTM model

Train, Validate, Evaluate: (Traditional team and Deep Learning Team 12/7)
Split data into training, validation, and test sets.
Evaluate using metrics like accuracy, F1-score, and ROC-AUC.
(Suggest branching out to SHAP values to help gain further understanding of the variables/words that are key to determine the difference between classes)

Storytelling, Conclusion, and Impact: (Eddie and Ryan 12/10)
Visualize findings using dashboards (e.g., graphs of detection rates, examples of fake vs. real content).
Summarize key insights and showcase how the system identifies patterns in fake news.
